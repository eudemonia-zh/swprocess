{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License Information\n",
    "---\n",
    "\n",
    "This file is distributed as part of `swprocess`, a Python package for surface wave processing.\n",
    "\n",
    "    Copyright (C) 2020 Joseph P. Vantassel (jvantassel@utexas.edu)\n",
    "\n",
    "    This program is free software: you can redistribute it and/or modify\n",
    "    it under the terms of the GNU General Public License as published by\n",
    "    the Free Software Foundation, either version 3 of the License, or\n",
    "    (at your option) any later version.\n",
    "\n",
    "    This program is distributed in the hope that it will be useful,\n",
    "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "    GNU General Public License for more details.\n",
    "\n",
    "    You should have received a copy of the GNU General Public License\n",
    "    along with this program.  If not, see <https: //www.gnu.org/licenses/>.\n",
    "    \n",
    "## About _swprocess_ and this notebook\n",
    "---\n",
    "\n",
    "`swprocess` is a Python package for surface wave processing. `swprocess` was developed by\n",
    "Joseph P. Vantassel under the supervision of Professor Brady R. Cox at The University of\n",
    "Texas at Austin.\n",
    "\n",
    "If you use _swprocess_ in your research or consulting, we ask you please cite the following:\n",
    "\n",
    "__TBD__\n",
    "\n",
    "<!-- >Joseph Vantassel. (2020). jpvantassel/hvsrpy: latest (Concept). Zenodo.\n",
    "[http://doi.org/10.5281/zenodo.3666956](http://doi.org/10.5281/zenodo.3666956)\n",
    " _Note: For software, version specific citations should be preferred to\n",
    "general concept citations, such as that listed above. To generate a version\n",
    "specific citation for `hvsrpy`, please use the citation tool on the `hvsrpy`\n",
    "[archive](http://doi.org/10.5281/zenodo.3666956)._\n",
    " -->\n",
    "\n",
    "<!-- The automated frequency-domain window-rejection algorithm and log-normal statistics\n",
    "implemented in `hvsrpy` were developed by Tianjian Cheng under the supervision of\n",
    "Professor Brady R. Cox at The University of Texas at Austin. To\n",
    "recognize their original work please cite the follwing:\n",
    "\n",
    "> Cox, B. R., Cheng, T., Vantassel, J. P., and Manuel, L. (2020). “A statistical\n",
    "> representation and frequency-domain window-rejection algorithm for single-station\n",
    "> HVSR measurements.” Geophysical Journal International, 221(3), 2170-2183.\n",
    "\n",
    "This notebook also provides automatic checking of the SESAME (2004) reliability\n",
    "and clarity critera. To recognize their original work please also cite the following:\n",
    "\n",
    "> SESAME. (2004). Guidelines for the Implementation of the H/V Spectral Ratio Technique on Ambient Vibrations\n",
    "> Measurements, Processing, and Interpretation. European Commission - Research General Directorate, 62,\n",
    "> European Commission - Research General Directorate.\n",
    " -->\n",
    " \n",
    "## Getting Started\n",
    "---\n",
    "1. Install _swprocess_ and its dependencies, with `pip install swprocess`. If you are not familiar with `pip`, a useful tutorial can be found [here](https://jpvantassel.github.io/python3-course/#/intro/pip). __(~3 minutes)__ \n",
    "\n",
    "__TBD__\n",
    "\n",
    "Happy Processing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import swprocess\n",
    "import swprepost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File(s) in the .json format to import. These files are produced as the output of the mam.ipynb and the masw.ipynb. You may also wish\n",
    "# to load .jsom files which contain the interatively trimmed experimental dispersion data produced by this notebook. See below for details.\n",
    "\n",
    "# Raw Data\n",
    "fnames_set = [\n",
    "    [\"../masw/wghs_masw.json\"],\n",
    "    [\"../mam/wghs_rayleigh_c50.json\"],\n",
    "    [\"../mam/wghs_rayleigh_bigx.json\"]\n",
    "    ]\n",
    "\n",
    "# # Processed Data\n",
    "# fnames_set = [\n",
    "#     [\"wghs_processed_masw.json\"],\n",
    "#     [\"wghs_processed_c50.json\"],\n",
    "#     [\"wghs_processed_bigx.json\"]\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domains in which to plot the experimental dispersion data.\n",
    "domains = [\n",
    "    [\"frequency\", \"velocity\"],\n",
    "    [\"wavelength\", \"velocity\"],\n",
    "]\n",
    "\n",
    "# Colors one per `fnames_set` entry. Examples include: \"limegreen\", \"dodgerblue\", \"tomatoe\", \"darkorange\".\n",
    "# A full listing is provided here: https://matplotlib.org/3.1.0/_images/sphx_glr_named_colors_003.png\n",
    "# Colors may also be listed in hexidecimal.\n",
    "colors = [\"limegreen\", \"dodgerblue\", \"tomato\"]\n",
    "\n",
    "# Labels one per `fnames_set` entry.\n",
    "labels = [\"MASW\", \"MAM - C50\", \"MAM - BigX\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Raw Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "xtype = [x for x, _ in domains]\n",
    "ytype = [y for _, y in domains]\n",
    "\n",
    "if len(fnames_set) != len(colors) or len(fnames_set) != len(labels):\n",
    "    raise IndexError(f\"fnames_set, colors, and labels must be the same length.\")\n",
    "\n",
    "fig, axs = plt.subplots(ncols=len(xtype), figsize=(6,3), dpi=150, gridspec_kw=dict(wspace=0.4))\n",
    "suites = []\n",
    "for fnames, color, label in zip(fnames_set, colors, labels):\n",
    "    peaksuite = swprocess.PeaksSuite.from_json(fnames=fnames)\n",
    "    peaksuite.plot(xtype=xtype, ax=axs, ytype=ytype, plot_kwargs=dict(color=color, label=label))\n",
    "    suites.append(peaksuite)\n",
    "    \n",
    "axs[-1].legend(bbox_to_anchor = (1.1, 0.5), loc=\"center left\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "master_suite = swprocess.PeaksSuite.from_peakssuite(suites)\n",
    "_colors, _labels = [], []\n",
    "for color, label, suite in zip(colors, labels, suites):\n",
    "    for _ in range(len(suite)):\n",
    "        _colors.append(color)\n",
    "        _labels.append(label)\n",
    "        label = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Trimming\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow for interactive trimming {\"individual\", \"together\"}, \"individual\" is recommended.\n",
    "workflow = \"individual\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array Resolution Limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolution limits, one per entry in fnames_set. Ingored if workflow=\"together\".\n",
    "individual_resolution_limits = [\n",
    "    [\"wavelength\", (2, 50)],\n",
    "    [\"wavenumber\", (0.103/2, 0.246*2)],\n",
    "    [\"wavenumber\", (0.0639154/2, 0.12635*2)],\n",
    "    ]\n",
    "\n",
    "# Overall minimumm and maximum array resolution, only one entry permitted.\n",
    "overall_resolution_limits = [\"wavenumber\", (0.103/2, 2*np.pi/2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bulk Trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bulk remove points outside of the specified screening criteria. Use `None` for one sided intervals. Multiple entries permitted.\n",
    "bulk_trimming_limits = {\n",
    "    \"velocity\" : [None, None],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "for suite in suites:\n",
    "    for attribute, limits in bulk_trimming_limits.items():\n",
    "        suite.blitz(attribute, limits)        \n",
    "\n",
    "if workflow == \"individual\":\n",
    "    if len(fnames_set) != len(individual_resolution_limits):\n",
    "        raise IndexError(f\"individidual_resolution_limits must have the same length as fnames_set.\")\n",
    "\n",
    "    for suite, color, label, _resolution_limits in zip(suites, colors, labels, individual_resolution_limits):\n",
    "        suite.interactive_trimming(xtype=xtype, ytype=ytype, plot_kwargs=dict(color=color, label=label), resolution_limits=_resolution_limits)\n",
    "\n",
    "master_suite.interactive_trimming(xtype=xtype, ytype=ytype, plot_kwargs=dict(color=_colors, label=_labels), resolution_limits=overall_resolution_limits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Data Post Trimming\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, axs = master_suite.plot(xtype=xtype, ytype=ytype, plot_kwargs=dict(color=_colors, label=_labels))\n",
    "\n",
    "for ax, _xtype, _ytype in zip(axs, xtype, ytype):\n",
    "    ax.autoscale(enable=False)\n",
    "    attribute, limits = overall_resolution_limits\n",
    "    master_suite.plot_resolution_limits(ax=ax, xtype=_xtype, ytype=_ytype, attribute=attribute, limits=limits, plot_kwargs=dict(label=\"Limits\"))\n",
    "    \n",
    "axs[-1].legend(bbox_to_anchor = (1.1, 0.5), loc=\"center left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "---\n",
    "\n",
    "TODO (jpv)\n",
    "- Number of points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain in which to calculate statistics.\n",
    "xdomain, ydomain = \"wavelength\", \"velocity\"\n",
    "\n",
    "# Statistic calculation points.\n",
    "xmin, xmax, nx, xspace = 1, 1000, 40, \"log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "xx = swprocess.wavefieldtransforms.AbstractWavefieldTransform._create_vector(pmin=xmin, pmax=xmax, pn=nx, pspace=xspace)\n",
    "xx, mean, stddev, _ = master_suite.statistics(xtype=xdomain, ytype=ydomain, xx=xx, ignore_corr=True, drop_sample_if_fewer_count=1)\n",
    "\n",
    "fig, axs = master_suite.plot(xtype=xtype, ytype=ytype, plot_kwargs=dict(color=_colors, label=_labels))\n",
    "\n",
    "for ax, _xtype, _ytype in zip(axs, xtype, ytype):\n",
    "    if _xtype == xdomain and _ytype == ydomain:\n",
    "        master_suite.plot_statistics(ax=ax, xx=xx, mean=mean, stddev=stddev)\n",
    "\n",
    "axs[-1].legend(bbox_to_anchor = (1.1, 0.5), loc=\"center left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to Experimental Dispersion Curve to `.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"wghs_rayleigh_0.txt\"\n",
    "version = \"2\"\n",
    "minimum_cov = 0.05\n",
    "\n",
    "if xdomain == \"frequency\" and ydomain == \"velocity\":\n",
    "    new_xx = np.array(xx)\n",
    "    new_mean = np.array(mean)\n",
    "    new_stddev = np.array(stddev)\n",
    "elif xdomain == \"wavelength\" and ydomain == \"velocity\":\n",
    "    new_xx = mean/xx\n",
    "    new_mean = np.array(mean)\n",
    "    upper = swprepost.Curve(x=(mean+stddev)/xx, y=mean+stddev)\n",
    "    lower = swprepost.Curve(x=(mean-stddev)/xx, y=mean-stddev)\n",
    "    new_stddev = ((upper.resample(xx=new_xx, interp1d_kwargs=dict(fill_value=\"extrapolate\"))[1] - new_mean) + (new_mean - lower.resample(xx=new_xx, interp1d_kwargs=dict(fill_value=\"extrapolate\"))[1])) /2\n",
    "else:\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "%matplotlib inline\n",
    "fig, axs = master_suite.plot(xtype=xtype, ytype=ytype, plot_kwargs=dict(color=_colors, label=_labels))\n",
    "\n",
    "for ax, _xtype, _ytype in zip(axs, xtype, ytype):\n",
    "    if _xtype == \"frequency\" and _ytype == \"velocity\":\n",
    "        master_suite.plot_statistics(ax=ax, xx=new_xx, mean=new_mean, stddev=new_stddev, errorbar_kwargs=dict(label=\"Exp. Disp. Data\"))\n",
    "\n",
    "for index, _stddev in enumerate(new_stddev):\n",
    "    if np.isnan(_stddev):\n",
    "        new_stddev[index] = 0\n",
    "\n",
    "target = swprepost.Target(frequency=new_xx, velocity=new_mean, velstd=new_stddev)\n",
    "target.setmincov(minimum_cov)\n",
    "ylabel = axs[0].get_ylabel()\n",
    "target.plot(ax=axs[0], errorbarkwargs=dict(color=\"r\", label=f\"Exp. Disp. Data (minCOV={minimum_cov})\"))\n",
    "axs[0].set_ylabel(ylabel)\n",
    "target.to_txt_dinver(fname=fname, version=version)\n",
    "\n",
    "axs[0].legend(bbox_to_anchor = (2.4, 0.5), loc=\"center left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to trimmed data to `.json`\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File contents {\"together\", \"indivdual\"}. \"together\" all sets are combined into a single file. \"individual\" all sets are saved to separate files.\n",
    "file_contents = \"individual\"\n",
    "\n",
    "# Output prefix.\n",
    "output_prefix = \"wghs_processed\"\n",
    "\n",
    "# If file_contents == \"indivdual\", define unique suffixes for each output file.\n",
    "output_suffixes = [\"masw\", \"c50\", \"bigx\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file_contents == \"together\":\n",
    "    master_suite.to_json(f\"{output_prefix}.json\")\n",
    "else:\n",
    "    if len(output_suffixes) != len(suites):\n",
    "        raise IndexError(f\"suites and indivdual suffixes are of different length.\")\n",
    "    for suite, suffix in zip(suites, output_suffixes):\n",
    "        suite.to_json(f\"{output_prefix}_{suffix}.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
